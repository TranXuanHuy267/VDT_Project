{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18041,
     "status": "ok",
     "timestamp": 1684779192890,
     "user": {
      "displayName": "Huy Tran Xuan",
      "userId": "11664675075409793997"
     },
     "user_tz": -420
    },
    "id": "f0i1gvS1qfTf",
    "outputId": "336dc77d-64b6-4b9e-dc8d-7da7e9ec0a87"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1684779192891,
     "user": {
      "displayName": "Huy Tran Xuan",
      "userId": "11664675075409793997"
     },
     "user_tz": -420
    },
    "id": "NoQA4g2qYbZp"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/content/drive/MyDrive/Main Project VDT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8924,
     "status": "ok",
     "timestamp": 1684779205787,
     "user": {
      "displayName": "Huy Tran Xuan",
      "userId": "11664675075409793997"
     },
     "user_tz": -420
    },
    "id": "UvqqW9zcbmCr",
    "outputId": "457d7bbf-5788-4c2d-cec3-f554ab2f6cc1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of id: 1000\n"
     ]
    }
   ],
   "source": [
    "# identification list\n",
    "ids = []\n",
    "for id in os.listdir(\"WebFace260M\"):\n",
    "    if id.startswith(\"0_0_\"):\n",
    "        ids.append(id)\n",
    "print(\"Number of id:\", len(ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 92892,
     "status": "ok",
     "timestamp": 1684779301846,
     "user": {
      "displayName": "Huy Tran Xuan",
      "userId": "11664675075409793997"
     },
     "user_tz": -420
    },
    "id": "fS_MFcNGfmYN"
   },
   "outputs": [],
   "source": [
    "# data set: set[id] = {file_name.jpg}\n",
    "instances = {}\n",
    "for id in ids:\n",
    "    instances[id] = []\n",
    "    for instance in os.listdir(\"WebFace260M/\"+id):\n",
    "        instances[id].append(instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 338,
     "status": "ok",
     "timestamp": 1684749181289,
     "user": {
      "displayName": "Huy Trần Xuân",
      "userId": "13850776301425990274"
     },
     "user_tz": -420
    },
    "id": "01u_2eT0gqIs",
    "outputId": "9c65a22e-6867-4d58-a515-b5ffd55cb3d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data:  19396\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def train_val_test_split()\n",
    "stats = list([len(instance) for instance in instances.values()])\n",
    "print(\"Number of data: \", sum(stats))\n",
    "stats.count(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jz7RoYqF6cEj"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "class Imdataset(Dataset):\n",
    "    def __init__(self, instances, transform=None):\n",
    "        super().__init__()\n",
    "        self.instances = instances\n",
    "        if transform is not None:\n",
    "            self.instances = [(transform(image), label) for image, label in instances] \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.instances)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.instances[index]\n",
    "\n",
    "    def collate_fn(self, batch):\n",
    "        images = []\n",
    "        labels = []\n",
    "        for inst in batch:\n",
    "            images.append(inst[0])\n",
    "            labels.append(inst[1])\n",
    "        images = torch.tensor(images)\n",
    "        labels = torch.tensor(labels)\n",
    "        return [images, labels]\n",
    "\n",
    "def collect_images(task, split_ratio, number_id):\n",
    "    dataset = []\n",
    "    assert task in [\"Train\", \"Valid\", \"Test\"]\n",
    "    folder_dir = \"WebFace260M\"\n",
    "    assert number_id < len(os.listdir(folder_dir))\n",
    "    for id in tqdm(os.listdir(folder_dir)[:number_id]):\n",
    "        id_images = os.listdir(folder_dir + \"/\" + id)\n",
    "        id_images_num = len(id_images)\n",
    "        test_num = int(split_ratio[\"Test\"]*id_images_num)\n",
    "        valid_num = int(split_ratio[\"Valid\"]*id_images_num)\n",
    "        if task==\"Train\":\n",
    "            images = id_images[:id_images_num - valid_num - test_num]\n",
    "        elif task==\"Valid\":\n",
    "            images = id_images[id_images_num - valid_num - test_num:id_images_num - test_num]\n",
    "        else:\n",
    "            images = id_images[id_images_num - test_num:]\n",
    "        \n",
    "        for images in os.listdir(folder_dir + \"/\" + id):\n",
    "            if images.endswith(\".jpg\"):\n",
    "                dataset.append(tuple([Image.open(folder_dir + \"/\" + id + \"/\" + images).convert('RGB'), int(id[4:])]))\n",
    "\n",
    "    return dataset\n",
    "\n",
    "def prepare_data(number_id=10, batch_size=4, num_workers=2, split_ratio=None, train_sample_size=None, valid_sample_size=None, test_sample_size=None):\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Resize((90, 90)),\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.RandomResizedCrop((90, 90), scale=(0.8, 1.0), ratio=(0.75, 1.3333333333333333), interpolation=2),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "\n",
    "    trainset = Imdataset(collect_images(\"Train\", split_ratio, number_id), train_transform)\n",
    "    if train_sample_size is not None:\n",
    "        indices = torch.randperm(len(trainset))[:train_sample_size]\n",
    "        trainset = torch.utils.data.Subset(trainset, indices)\n",
    "    \n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                            shuffle=True, num_workers=num_workers)\n",
    "    \n",
    "    test_transform = transforms.Compose(\n",
    "        [transforms.ToTensor(),\n",
    "        transforms.Resize((90, 90)),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "\n",
    "    validset = Imdataset(collect_images(\"Valid\", split_ratio, number_id), test_transform)\n",
    "    \n",
    "    if valid_sample_size is not None:\n",
    "        indices = torch.randperm(len(validset))[:valid_sample_size]\n",
    "        validset = torch.utils.data.Subset(validset, indices)\n",
    "    \n",
    "    validloader = torch.utils.data.DataLoader(validset, batch_size=batch_size,\n",
    "                                            shuffle=False, num_workers=num_workers)\n",
    "\n",
    "\n",
    "    testset = Imdataset(collect_images(\"Test\", split_ratio, number_id), test_transform)\n",
    "    \n",
    "    if test_sample_size is not None:\n",
    "        # Randomly sample a subset of the test set\n",
    "        indices = torch.randperm(len(testset))[:test_sample_size]\n",
    "        testset = torch.utils.data.Subset(testset, indices)\n",
    "    \n",
    "    testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                            shuffle=False, num_workers=num_workers)\n",
    "\n",
    "    return trainloader, validloader, testloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 586,
     "status": "ok",
     "timestamp": 1684753073019,
     "user": {
      "displayName": "Huy Trần Xuân",
      "userId": "13850776301425990274"
     },
     "user_tz": -420
    },
    "id": "44g5vir6GdA3",
    "outputId": "40f99e9d-57f2-45e1-8722-eab55e91c589"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3528"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5879,
     "status": "ok",
     "timestamp": 1684753138115,
     "user": {
      "displayName": "Huy Trần Xuân",
      "userId": "13850776301425990274"
     },
     "user_tz": -420
    },
    "id": "x1Ejl5A8FFpq",
    "outputId": "3bd92061-f3cd-4fb3-ffcc-65ea4fc66dcc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 10.33it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 10.11it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 10.17it/s]\n"
     ]
    }
   ],
   "source": [
    "split_ratio = {\"Train\": 0.7, \"Valid\": 0.2, \"Test\": 0.1}\n",
    "trainloader, valloader, testloader= prepare_data(number_id=10, batch_size=4, split_ratio=split_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "iiS7wbZvHQy7"
   },
   "outputs": [],
   "source": [
    "from models.vit import VisionTransformer\n",
    "import json\n",
    "from models.block import ParallelScalingBlock\n",
    "from models.norm import RmsNorm\n",
    "\n",
    "\n",
    "configfile = \"configs/test_config.json\"\n",
    "\n",
    "config = {\n",
    "    \"patch_size\": 14,\n",
    "    \"embed_dim\": 48*10, \n",
    "    \"depth\": 48,\n",
    "    \"num_heads\": 48,\n",
    "    \"pre_norm\": 1,\n",
    "    \"no_embed_class\": 1,\n",
    "    \"qkv_bias\": 0,\n",
    "    \"qk_norm\": 1\n",
    "}\n",
    "\n",
    "with open(configfile, 'w') as f:\n",
    "    sth = json.dumps(config, indent=4)\n",
    "    f.write(sth)\n",
    "\n",
    "\n",
    "with open(configfile, 'r') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "model_own = dict(\n",
    "    patch_size=config[\"patch_size\"], \n",
    "    embed_dim=config[\"embed_dim\"], \n",
    "    depth=config[\"depth\"], \n",
    "    num_heads=config[\"num_heads\"], \n",
    "    pre_norm=config[\"pre_norm\"], \n",
    "    no_embed_class=config[\"no_embed_class\"],\n",
    "    norm_layer=RmsNorm, \n",
    "    block_fn=ParallelScalingBlock, \n",
    "    qkv_bias=config[\"qkv_bias\"], \n",
    "    qk_norm=config[\"qk_norm\"],\n",
    ")\n",
    "\n",
    "vit = VisionTransformer(**model_own)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "133760200"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_params = sum(params.numel() for params in vit.parameters())\n",
    "total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "6144/48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              total        used        free      shared  buff/cache   available\n",
      "Mem:          251Gi        64Gi       171Gi       328Mi        16Gi       185Gi\n",
      "Swap:          11Gi       2.9Gi       9.1Gi\n"
     ]
    }
   ],
   "source": [
    "# memory before storing model\n",
    "!free -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              total        used        free      shared  buff/cache   available\n",
      "Mem:          251Gi        67Gi       168Gi       328Mi        16Gi       182Gi\n",
      "Swap:          11Gi       2.9Gi       9.1Gi\n"
     ]
    }
   ],
   "source": [
    "# memory after storing model\n",
    "!free -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue May 23 21:20:57 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.106.00   Driver Version: 460.106.00   CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  A40                 On   | 00000000:81:00.0 Off |                    0 |\n",
      "|  0%   61C    P0    93W / 300W |  25379MiB / 45634MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue May 23 21:12:34 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.106.00   Driver Version: 460.106.00   CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  A40                 On   | 00000000:81:00.0 Off |                    0 |\n",
      "|  0%   77C    P0   115W / 300W |  25379MiB / 45634MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
